#Author's name
#Yash Jaiswal - BT18ECE014
#Varun Ramteke - BT18ECE073
#Romal Gaikwad -BT17ECE069
#Raman Kedar - BT18ECE006
#Yash Chandekar - BT18ECE127
# GUI module generated by PAGE version 6.2
#  in conjunction with Tcl version 8.6
#    Apr 05, 2022 07:34:11 PM IST  platform: Windows NT

# YOLOv5 by Ultralytics, GPL-3.0 license
"""
Run inference on images, videos, directories, streams, etc.

Usage:
    $ python path/to/detect.py --source path/to/img.jpg --weights yolov5s.pt --img 640
"""


import time
from pathlib import Path
import math
import cv2
import numpy as np
import torch
import torch.backends.cudnn as cudnn
import requests,imutils
from PIL import Image, ImageTk
import json
import gspread
import json
from oauth2client.service_account import ServiceAccountCredentials
import datetime


global config_dict
fp =open('config.json',"r")
config_dict = json.loads(fp.read())
fp.close()

# FILE = Path(__file__).absolute()
# sys.path.append(FILE.parents[0].as_posix())  # add yolov5/ to path

from models.experimental import attempt_load
from utils.datasets import LoadStreams, LoadImages
from utils.general import check_img_size, check_requirements, check_imshow, colorstr, is_ascii, non_max_suppression, \
    apply_classifier, scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path, save_one_box
from utils.plots import Annotator, colors
from utils.torch_utils import select_device, load_classifier, time_sync
class yolov5:
    def __init__(self,weights='yolov5s.pt',  # model.pt path(s)
        source='data/images',  # file/dir/URL/glob, 0 for webcam
        imgsz=640,  # inference size (pixels)
        conf_thres=0.25,  # confidence threshold
        iou_thres=0.45,  # NMS IOU threshold
        max_det=1000,  # maximum detections per image
        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu
        view_img=False,  # show results
        save_txt=False,  # save results to *.txt
        save_conf=False,  # save confidences in --save-txt labels
        save_crop=False,  # save cropped prediction boxes
        nosave=False,  # do not save images/videos
        classes=None,  # filter by class: --class 0, or --class 0 2 3
        agnostic_nms=False,  # class-agnostic NMS
        augment=False,  # augmented inference
        visualize=False,  # visualize features
        update=False,  # update all models
        project='runs/detect',  # save results to project/name
        name='exp',  # save results to project/name
        exist_ok=False,  # existing project/name ok, do not increment
        line_thickness=3,  # bounding box thickness (pixels)
        hide_labels=False,  # hide labels
        hide_conf=False,  # hide confidences
        half=False,  # use FP16 half-precision inference
                ):
        self.weights=weights  # model.pt path(s)
        source=source  # file/dir/URL/glob, 0 for webcam
        self.imgsz=imgsz  # inference size (pixels)
        self.conf_thres=conf_thres  # confidence threshold
        self.iou_thres=iou_thres  # NMS IOU threshold
        self.max_det=max_det  # maximum detections per image
        self.device=device  # cuda device, i.e. 0 or 0,1,2,3 or cpu
        view_img=view_img  # show results
        self.save_txt=save_txt  # save results to *.txt
        self.save_conf=save_conf  # save confidences in --save-txt labels
        self.save_crop=save_crop  # save cropped prediction boxes
        nosave=nosave  # do not save images/videos
        self.classes=classes  # filter by class: --class 0, or --class 0 2 3
        self.agnostic_nms=agnostic_nms  # class-agnostic NMS
        self.augment=augment  # augmented inference
        self.visualize=visualize  # visualize features
        self.update=update  # update all models
        project=project  # save results to project/name
        name=name  # save results to project/name
        exist_ok=exist_ok  # existing project/name ok, do not increment
        self.line_thickness=line_thickness  # bounding box thickness (pixels)
        self.hide_labels=hide_labels  # hide labels
        self.hide_conf=hide_conf  # hide confidences
        self.half=half 
        self.save_img = not nosave and not source.endswith('.txt')  # save inference images
        self.webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(
            ('rtsp://', 'rtmp://', 'http://', 'https://'))

        # Directories
        self.save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run
        (self.save_dir / 'labels' if self.save_txt else self.save_dir).mkdir(parents=True, exist_ok=True)  # make dir

        # Initialize
        set_logging()
        self.device = select_device(self.device)
        self.half &= self.device.type != 'cpu'  # half precision only supported on CUDA

        # Load model
        w = self.weights[0] if isinstance(self.weights, list) else self.weights
        self.classify, suffix = False, Path(w).suffix.lower()
        self.pt, self.onnx, self.tflite, self.pb, self.saved_model = (suffix == x for x in ['.pt', '.onnx', '.tflite', '.pb', ''])  # backend
        self.stride, self.names = 64, [f'class{i}' for i in range(1000)]  # assign defaults
        if self.pt:
            self.model = attempt_load(self.weights, map_location=self.device)  # load FP32 model
            self.stride = int(self.model.stride.max())  # model stride
            self.names = self.model.module.names if hasattr(self.model, 'module') else self.model.names  # get class names
            if self.half:
                self.model.half()  # to FP16
            if self.classify:  # second-stage classifier
                modelc = load_classifier(name='resnet50', n=2)  # initialize
                modelc.load_state_dict(torch.load('resnet50.pt', map_location=self.device)['model']).to(self.device).eval()
        elif self.onnx:
            check_requirements(('onnx', 'onnxruntime'))
            import onnxruntime
            self.session = onnxruntime.InferenceSession(w, None)
        else:  # TensorFlow models
            check_requirements(('tensorflow>=2.4.1',))
            import tensorflow as tf
            if self.pb:  # https://www.tensorflow.org/guide/migrate#a_graphpb_or_graphpbtxt
                def wrap_frozen_graph(gd, inputs, outputs):
                    x = tf.compat.v1.wrap_function(lambda: tf.compat.v1.import_graph_def(gd, name=""), [])  # wrapped import
                    return x.prune(tf.nest.map_structure(x.graph.as_graph_element, inputs),
                                   tf.nest.map_structure(x.graph.as_graph_element, outputs))

                graph_def = tf.Graph().as_graph_def()
                graph_def.ParseFromString(open(w, 'rb').read())
                self.frozen_func = wrap_frozen_graph(gd=graph_def, inputs="x:0", outputs="Identity:0")
            elif self.saved_model:
                self.model = tf.keras.models.load_model(w)
            elif self.tflite:
                self.interpreter = tf.lite.Interpreter(model_path=w)  # load TFLite model
                self.interpreter.allocate_tensors()  # allocate
                self.input_details = self.interpreter.get_input_details()  # inputs
                self.output_details = self.interpreter.get_output_details()  # outputs
                self.int8 = self.input_details[0]['dtype'] == np.uint8  # is TFLite quantized uint8 model
        self.imgsz = check_img_size(self.imgsz, s=self.stride)  # check image size
        # ascii = is_ascii(self.names)  # names are ascii (use PIL for UTF-8)
        if self.pt and self.device.type != 'cpu':
            self.model(torch.zeros(1, 3, *self.imgsz).to(self.device).type_as(next(self.model.parameters())))  # run once
    def run(self,source):
         # Dataloader
        self.source = source
        import tensorflow as tf
        if self.webcam:
            view_img = check_imshow()
            cudnn.benchmark = True  # set True to speed up constant image size inference
            dataset = LoadStreams(source, img_size=self.imgsz, stride=self.stride, auto=self.pt)
            bs = len(dataset)  # batch_size
        else:
            dataset = LoadImages(source, img_size=self.imgsz, stride=self.stride, auto=self.pt)
            bs = 1  # batch_size
        vid_path, vid_writer = [None] * bs, [None] * bs
        for path, img, im0s, vid_cap in dataset:
            if self.onnx:
                img = img.astype('float32')
            else:
                img = torch.from_numpy(img).to(self.device)
                img = img.half() if self.half else img.float()  # uint8 to fp16/32
            img = img / 255.0  # 0 - 255 to 0.0 - 1.0
            if len(img.shape) == 3:
                img = img[None]  # expand for batch dim

            # Inference
            t1 = time_sync()
            if self.pt:
                self.visualize = increment_path(self.save_dir / Path(path).stem, mkdir=True) if self.visualize else False
                pred = self.model(img, augment=self.augment, visualize=self.visualize)[0]
            elif self.onnx:
                pred = torch.tensor(self.session.run([self.session.get_outputs()[0].name], {self.session.get_inputs()[0].name: img}))
            else:  # tensorflow model (tflite, pb, saved_model)
                imn = img.permute(0, 2, 3, 1).cpu().numpy()  # image in numpy
                if self.pb:
                    pred = self.frozen_func(x=tf.constant(imn)).numpy()
                elif self.saved_model:
                    pred = self.model(imn, training=False).numpy()
                elif self.tflite:
                    if self.int8:
                        scale, zero_point = self.input_details[0]['quantization']
                        imn = (imn / scale + zero_point).astype(np.uint8)  # de-scale
                    self.interpreter.set_tensor(self.input_details[0]['index'], imn)
                    self.interpreter.invoke()
                    pred = self.interpreter.get_tensor(self.output_details[0]['index'])
                    if self.int8:
                        scale, zero_point = self.output_details[0]['quantization']
                        pred = (pred.astype(np.float32) - zero_point) * scale  # re-scale
                pred[..., 0] *= self.imgsz[1]  # x
                pred[..., 1] *= self.imgsz[0]  # y
                pred[..., 2] *= self.imgsz[1]  # w
                pred[..., 3] *= self.imgsz[0]  # h
                pred = torch.tensor(pred)

            # NMS
            pred = non_max_suppression(pred, self.conf_thres, self.iou_thres, self.classes, self.agnostic_nms, max_det=self.max_det)
            t2 = time_sync()

            # Second-stage classifier (optional)
            if self.classify:
                pred = apply_classifier(pred, self.modelc, img, im0s)

            # Process predictions
            for i, det in enumerate(pred):  # detections per image
                if self.webcam:  # batch_size >= 1
                    p, s, im0, frame = path[i], f'{i}: ', im0s[i].copy(), dataset.count
                else:
                    p, s, im0, frame = path, '', im0s.copy(), getattr(dataset, 'frame', 0)

                p = Path(p)  # to Path
                save_path = str(self.save_dir / p.name)  # img.jpg
                txt_path = str(self.save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt
                s += '%gx%g ' % img.shape[2:]  # print string
                gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
                imc = im0.copy() if self.save_crop else im0  # for save_crop
                annotator = Annotator(im0, line_width=self.line_thickness, pil=not ascii)
                detection_list = list()
                if len(det):
                    # Rescale boxes from img_size to im0 size
                    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()

                    # Print results
                    for c in det[:, -1].unique():
                        n = (det[:, -1] == c).sum()  # detections per class
                        s += f"{n} {self.names[int(c)]}{' ' * (n > 1)}, "  # add to string
                    # Write results
                    for *xyxy, conf, cls in reversed(det):
                        if self.save_txt:  # Write to file
                            xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                            # print(xywh)
                            line = (cls, *xywh, conf) if self.save_conf else (cls, *xywh)  # label format
                            with open(txt_path + '.txt', 'a') as f:
                                f.write(('%g ' * len(line)).rstrip() % line + '\n')

                        if self.save_img or self.save_crop or view_img:  # Add bbox to image
                            c = int(cls)  # integer class
                            label = None if self.hide_labels else (self.names[c] if self.hide_conf else f'{self.names[c]} {conf:.2f}')
                            xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4))).view(-1).tolist()  # normalized xywh
                            detection_list.append(list(map(int, list(xyxy))))
    #                         print(list(xyxy))
                            annotator.box_label(xyxy, label, color=colors(c, True))
                            if self.save_crop:
                                save_one_box(xyxy, imc, file=self.save_dir / 'crops' / self.names[c] / f'{p.stem}.jpg', BGR=True)
                return(detection_list)
                # Print time (inference + NMS)
                # print(f'{s}Done. ({t2 - t1:.3f}s)')

                # Stream results
                im0 = annotator.result()
                if view_img:
                    cv2.imshow(str(p), im0)
                    cv2.waitKey(0)  # 1 millisecond

                # Save results (image with detections)
                if self.save_img:
                    if dataset.mode == 'image':
                        cv2.imwrite(save_path, im0)
                    else:  # 'video' or 'stream'
                        if vid_path[i] != save_path:  # new video
                            vid_path[i] = save_path
                            if isinstance(vid_writer[i], cv2.VideoWriter):
                                vid_writer[i].release()  # release previous video writer
                            if vid_cap:  # video
                                fps = vid_cap.get(cv2.CAP_PROP_FPS)
                                w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                                h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                            else:  # stream
                                fps, w, h = 30, im0.shape[1], im0.shape[0]
                                save_path += '.mp4'
                            vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))
                        vid_writer[i].write(im0)

        if self.save_txt or self.save_img:
            s = f"\n{len(list(self.save_dir.glob('labels/*.txt')))} labels saved to {self.save_dir / 'labels'}" if self.save_txt else ''
            # print(f"Results saved to {colorstr('bold', self.save_dir)}{s}")

        if self.update:
            strip_optimizer(self.weights)  # update model (to fix SourceChangeWarning)

        
global yolo
yolo = yolov5(agnostic_nms=False, augment=False, classes=None, conf_thres=0.25, device='', exist_ok=False, 
                        half=False, hide_conf=False, hide_labels=False, imgsz=[640, 640], 
                        iou_thres=0.45, line_thickness=3, max_det=1000, name='exp', nosave=False, 
                        project='runs/detect', save_conf=False, save_crop=False, save_txt=False, 
                        source='temp.jpg', update=False, view_img=False, 
                        visualize=False, weights=['runs/train/exp12/weights/best.pt'])



            
######################################################################################################
class EuclideanDistTracker:
    def __init__(self):
        # Store center positions of the car
        self.center_points = {}
        # store the count of different IDs
        self.id_count = 0
        
    def vert_callib(self,y,h,vfov,angle):
        point_angle = (vfov/2)-((y/360)*vfov)
        fin_angle = angle + point_angle
        dist = h * math.tan(fin_angle)
        return(dist)
    
    def speed2(self, FPS, frame_count_1,frame_count_2,distance_between_region):
        global cam_mode
        if cam_mode == 2:
            time_speed = (frame_count_2 - frame_count_1)/FPS
        else:
            time_speed = (frame_count_2 - frame_count_1)
        v = distance_between_region/time_speed * 3.6
        return int(v)
        
    def update(self, objects_rect,FPS,region_line_up,region_line_down,distance_between_region,f_count,t2):
        # Objects boxes and ids
        global speed_limit,cam_mode,pixel_limit_bw_cars,sheet,sheet_pointer
        time_stamp = t2
        if(cam_mode == 2):
            t2=f_count
        objects_bbs_ids = []
        #pole parameters
        #Camera specs
        x = 640
        y = 360
        # Get center point of new object
        # dirn = True
        
        for rect in objects_rect:
            x, y, w, h = rect
            cx = (x + x + w) // 2
            cy = (y + y + h) // 2
            new_bump_coord = y+h

            # check if the car is detected already
            same_object_detected = False
            for id, pt in self.center_points.items():
                #calculating EuclideanDist using hypotenuse function
                dist = math.hypot(cx - pt[0], cy - pt[1])
                
                if dist < pixel_limit_bw_cars:
                    (cx1,cy1,t1,distance_done,v2,bumper_coord,violation) = self.center_points[id]
                    if(new_bump_coord >= region_line_up and t1 == 0):
                        self.center_points[id] = (cx, cy,t2, False,0,new_bump_coord,violation)
                    elif (new_bump_coord >= region_line_down):
                        #adding 200 as the region is of ROI not the whole frame
#                         v = self.speed(cy,cy1,height,vfov,angle,30)
                        if(distance_done):
                            self.center_points[id] = (cx, cy,t1, distance_done,v2,new_bump_coord,violation)
                        else:
                            
                            v2 = self.speed2(FPS, t1,t2,distance_between_region)
                            if(v2>speed_limit):
                                violation = 1
                                #record the violation in the database
                                # time_stamp1 = t1
                                # time_stamp2 = t2
                                #x,y,w,h
                                #distance_between_region
                                #speed
                                time_stamp1 = time_stamp - (abs(t2-t1)/FPS)
                                sheet.update_cell(sheet_pointer, 1, sheet_pointer-1)
                                if(cam_mode == 2):
                                    sheet.update_cell(sheet_pointer, 2, str(datetime.datetime.fromtimestamp( time_stamp1 )) ) ##Update cell
                                    sheet.update_cell(sheet_pointer, 3, str(datetime.datetime.fromtimestamp( time_stamp )) )
                                else:
                                    sheet.update_cell(sheet_pointer, 2, str(datetime.datetime.fromtimestamp( t1 )) ) ##Update cell
                                    sheet.update_cell(sheet_pointer, 3, str(datetime.datetime.fromtimestamp( t2)) )
                                sheet.update_cell(sheet_pointer, 4, x)
                                sheet.update_cell(sheet_pointer, 5, y)
                                sheet.update_cell(sheet_pointer, 6, w)
                                sheet.update_cell(sheet_pointer, 7, h)
                                sheet.update_cell(sheet_pointer, 8, distance_between_region)
                                sheet.update_cell(sheet_pointer, 9, v2)
                                sheet.update_cell(sheet_pointer, 10, uploadFilesTo_G_Drive('temp.jpg', auth_token))
                                sheet_pointer +=1
                                
                            distance_done = True
                            self.center_points[id] = (cx, cy,t2, distance_done,v2,new_bump_coord,violation)
                    else:
                        self.center_points[id] = (cx, cy,t1, False,0,new_bump_coord,violation)
#                     print(self.center_points)
                    objects_bbs_ids.append([x, y, w, h, id,v2,violation])
#                     if(distance_done):
#                         objects_bbs_ids.append([x, y, w, h, id,v2,dirn])
#                     else:
#                         objects_bbs_ids.append([x, y, w, h, id,0,dirn])
                    same_object_detected = True
                    break

            # If new car detected, assign the ID
            if (same_object_detected is False)and (new_bump_coord < region_line_up):
                self.center_points[self.id_count] = (cx, cy, 0, False,0,new_bump_coord,0)
                objects_bbs_ids.append([x, y, w, h, self.id_count,0,False])
                self.id_count += 1
            
            
        # Remove the trash Ids
        new_center_points = {}
        for obj_bb_id in objects_bbs_ids:
            _, _, _, _, object_id,_,_ = obj_bb_id
            center = self.center_points[object_id]
            new_center_points[object_id] = center

        # Update dictionary
        self.center_points = new_center_points.copy()
        return objects_bbs_ids
                

#check if the signal is crossed or not
def check_zebra_cross(y,h):
    y1 = (2*y+h)//2
    if y1 < 80:
        return((0,0,255))
    else:
        return((0,255,0))
    
def nothing(x):
    pass
##############################################################################################

def read_image():
    global cam,cam_mode,frame_count,ip_address
    if(cam_mode == 0):
        url = ip_address+"/shot.jpg"
        img_resp = requests.get(url)
        img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)
        img = cv2.imdecode(img_arr, -1)
        frame = imutils.resize(img, width=1000, height=1800)
        frame_count +=1
        return(frame,frame_count)
    else:
        ret,frame = cam.read()
    frame_count += 1
    return [frame,frame_count] 

##################################################################################################
#send to sheet
import gspread
import json
from oauth2client.service_account import ServiceAccountCredentials
global auth_token

auth_token = str(config_dict["auth_token"])
# print(type(auth_token))

def uploadFilesTo_G_Drive(img, auth_token):
    import json
    import requests
    headers = {"Authorization": "Bearer" + " " + auth_token}
    para = {
        "name": "temp.jpg",
        "parents": ["1S3wnv4PlBYiedBOpFA8C57eW6I4BKTFN"]
    }
    files = {
        'data': ('metadata', json.dumps(para), 'application/json; charset=UTF-8'),
        'file': open(f"./{img}", "rb")
    }
    r = requests.post(
        "https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart",
        headers=headers,
        files=files
    )
    # print(r.text)
    json_obj = json.loads(r.text)
    link = f'https://drive.google.com/file/d/{json_obj["id"]}/view'
    return link

def setup_database():
    global sheet,sheet_pointer,auth_token
    #----------------------------------------#
    
    # Google drive api
    # auth_token = 'ya29.A0ARrdaM_DpingZwqK6G8NwBszi7QUOexosRxgtVBDJWRyqJZN0ZkB_-8o_ENQAhQbZYj4b3PP9DxXcjGhPnZLBW65K5-EV9RXUXdV9k01U6XfWkRXyWwOAGzxLjzS6HXx5DwypeJwvwax2dJ39Ufb0mgAu7md'
    
    
    
    
    # Function to upload to g-drive
    
    
    #--------------------------------------------------------#
    
    # Read, write and update Sheet code
    scope = ["https://spreadsheets.google.com/feeds",'https://www.googleapis.com/auth/spreadsheets',"https://www.googleapis.com/auth/drive.file","https://www.googleapis.com/auth/drive"]
    
    creds = ServiceAccountCredentials.from_json_keyfile_name("sheet_auth.json", scope)
    
    client = gspread.authorize(creds)
    
    sheet = client.open("ML_project").sheet1 ##change to sheet2 or sheet3 if you want to create more sheets
    
    data = sheet.get_all_records()
    # print(data)
    sheet_pointer = (len(data))+2
    # print("sheet_pointer " ,sheet_pointer)
    if(len(data) ==0):
        sheet.clear()
        sheet.update_cell(1, 1, 'Sr No')
        sheet.update_cell(1, 2, 'Time Stamp 1')
        sheet.update_cell(1, 3, 'Time Stamp 2')
        sheet.update_cell(1, 4, 'X')
        sheet.update_cell(1, 5, 'Y')
        sheet.update_cell(1, 6, 'Width')
        sheet.update_cell(1, 7, 'Height')
        sheet.update_cell(1, 8, 'Distance')
        sheet.update_cell(1, 9, 'Speed')
        sheet.update_cell(1, 10, 'Link')
        sheet_pointer =2
    
#####################################################################################################
    
   
        
   
    
global frame_count,FPS,direction_mode
global region_line_up ,region_line_down,distance_between_region
global cam_mode,speed_limit
global pixel_limit_bw_cars
    
region_line_up = config_dict["region_line_up"]
region_line_down = config_dict["region_line_down"]
distance_between_region = config_dict["distance_between_region"]
FPS = 30
frame_count = 0
direction_mode = 0
cam_mode = 0
speed_limit = config_dict["speed_limit"]
pixel_limit_bw_cars = config_dict["pixel_limit_bw_cars"]
   
    
   
    
   
    
   
















try:
    import Tkinter as tk
except ImportError:
    import tkinter as tk

try:
    import ttk
    py3 = False
except ImportError:
    import tkinter.ttk as ttk
    py3 = True

from tkinter import filedialog







global tracker
global pause_flag
global play_flag
global cam
global filename,dirn,selected_filename,ip_address
selected_filename =''
# global cam_mode
ip_address = ''
tracker = EuclideanDistTracker()
# cam = cv2.VideoCapture("sample5.mp4")
dirn = 0
pause_flag = 0
play_flag = 0
cam_mode = 2
filename = 'sample5.mp4'

# print(dict(config_dict))


def setup_cam():
    global cam,filename,FPS,cam_mode,ip_address
    if(cam_mode ==0):
        pass
    elif(cam_mode == 1):
        cam = cv2.VideoCapture(0)
        FPS = 30
    else:
        try:
            cam.release()
        except:
            pass
        # print(filename)
        cam = cv2.VideoCapture(str(filename))
        FPS = int(cam.get(cv2.CAP_PROP_FPS))
        # print(FPS)

setup_cam()
setup_database()
root = tk.Tk()
# root = tk.Toplevel()
'''This class configures and populates the toplevel window.
   top is the toplevel containing window.'''
_bgcolor = '#d9d9d9'  # X11 color: 'gray85'
_fgcolor = '#000000'  # X11 color: 'black'
_compcolor = '#d9d9d9' # X11 color: 'gray85'
_ana1color = '#d9d9d9' # X11 color: 'gray85'
_ana2color = '#ececec' # Closest X11 color: 'gray92'

root.geometry("1920x991+-0+0")
root.attributes('-fullscreen', True)
root.minsize(148, 1)
root.maxsize(1924, 1055)
root.resizable(1,  1)
root.title("New rootlevel")
root.configure(background="#d9d9d9")
root.configure(highlightbackground="#d9d9d9")
root.configure(highlightcolor="black")

def playy():
    global play_flag,pause_flag
    play_flag = 1
    pause_flag = 0
    play_video()

def pausee():
    global play_flag,pause_flag
    pause_flag = 1
    play_flag = 0

def exitt():
    global config_dict
    print(config_dict)
    y = json.dumps(dict(config_dict),indent = 4)

    with open('config.json', 'w') as outfile:
        outfile.write(y)
    root.destroy()
    cam.release()



def play_video():
    global play_flag,pause_flag,frame_count,FPS
    global region_line_up ,region_line_down,distance_between_region
    global yolo,tracker,cam_mode
    global cam,dirn,image_height
    frame,frame_count = read_image()
    time_frame_count = time.time()
    ret = True
    # if(ret==True):
    height, width, _ = frame.shape
    image_height = height
    cv2.imwrite("temp.jpg", frame)
    detect = yolo.run("temp.jpg")
    detections = []
    color = (255,255,255)
    for m in detect:
        [x1, y1, x2, y2] = m
        x = x1
        y = y1
        w = abs(x2-x1)
        h = abs(y2-y1)
        box_color = check_zebra_cross(y,h)

        cx = (x1+x2)//2
        cy = (y1+y2)//2
        # if(cy < zebra_crossing):
        #     continue
        # if(not dirn):
        #     cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0), 3)
        # else:
        #     cv2.rectangle(frame,(x1,y1),(x2,y2),(0,0,255), 3)
        image = cv2.circle(frame, (cx,cy), radius=7, color=box_color, thickness=-1)#draw centroid
        if(box_color == (0,0,255)):#Indicate that if the vehicle crossed or not the signal
            cv2.putText(frame, "Crossed", (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 1, box_color,2)
        detections.append([x,y,w,h])
    
    boxes_ids = tracker.update(detections,FPS,region_line_up,region_line_down,distance_between_region,frame_count,time_frame_count)#update the detections
    # print(boxes_ids)
    for box_id in boxes_ids:
        x,y,w,h,id,v,dirn = box_id
        #indicate speed on the frame
        cv2.putText(frame, str(v), (x+w, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0),2)
        cv2.putText(frame, str(id), (x, y - 15), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0),2)
#         cv2.rectangle(roi,(x,y),(x+w,y+h),(0,255,0), 3)
        if(not dirn):
            cv2.rectangle(frame,(x,y),(x+w, y +h),(0,255,0), 3)
            cv2.putText(frame, "Right-way", (x+w, y +h +15), cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0),2)
        else:
            cv2.rectangle(frame,(x,y),(x+w, y +h),(0,0,255), 3)
            cv2.putText(frame, "Wrong-way", (x+w, y +h +15), cv2.FONT_HERSHEY_PLAIN, 2, (0,0,255),2)

        #for visual convinience created a line for signal jump projection
    # cv2.line(frame,(0,zebra_crossing),(width,zebra_crossing),color,9)
    cv2.line(frame,(0,region_line_up),(width,region_line_up),(0,0,0),5)
    cv2.line(frame,(0,region_line_down),(width,region_line_down),(0,0,0),5)
    cv2.putText(frame, str(frame_count), (25, 25), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0),2)
    # frame = cv2.resize(frame,(600,400),interpolation = cv2.INTER_AREA)
    
    if(play_flag):    
        # img = cam.read()[1]
        # print(img.shape)
        img = cv2.resize(frame,(1000,int(1000*frame.shape[0]/frame.shape[1])),interpolation = cv2.INTER_AREA)
        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGBA)
        # print("hi")
        img = ImageTk.PhotoImage(image = Image.fromarray(img))
        video_label.imgtk = img
        video_label.configure(image = img)
        # root.update()
        video_label.after(2, play_video)
        
        


#############################################################################################################
def camera_setting():
    global selected_filename,cam_mode,filename,ip_address
    selected_filename = ''
    def exit_camera_setting():
        camera_root.destroy()
    
    def browseFiles():
        global selected_filename
        selected_filename = filedialog.askopenfilename(initialdir = "/",
                                              title = "Select a File",
                                              filetypes = (("Video files",
                                                            "*.mp4*"),
                                                           ("all files",
                                                            "*.*")))
        fileDestiButton.configure(text=str(selected_filename))
        
    def apply_camera_settings():
        global cam_mode,filename,ip_address,selected_filename,frame_count
        if(len(cameraModeList.curselection())>0):
        # print(Listbox_input_mode.curselection()[0])
            cam_mode = int(cameraModeList.curselection()[0])
            frame_count = 0
            
        else:
            cam_mode = 2
        
        if(len(str(selected_filename))>0 and cam_mode == 2):
            filename = selected_filename
            frame_count = 0
        else:
            pass
        
        if(len(camInput.get())>0 and cam_mode == 0):
            ip_address = str(camInput.get())
            frame_count = 0
        else:
            ip_address = ''
            
        setup_cam()
        play_video()
        
        
    '''This class configures and populates the rootlevel window.
       root is the rootlevel containing window.'''
    camera_root = tk.Toplevel(root)
    _bgcolor = '#d9d9d9'  # X11 color: 'gray85'
    _fgcolor = '#000000'  # X11 color: 'black'
    _compcolor = '#d9d9d9' # X11 color: 'gray85'
    _ana1color = '#d9d9d9' # X11 color: 'gray85'
    _ana2color = '#ececec' # Closest X11 color: 'gray92'

    camera_root.geometry("452x346+531+134")
    camera_root.minsize(120, 1)
    camera_root.maxsize(1540, 845)
    camera_root.resizable(1,  1)
    camera_root.title("camera_rootlevel 1")
    camera_root.configure(background="#d9d9d9")
    camera_root.configure(highlightbackground="#d9d9d9")
    camera_root.configure(highlightcolor="black")


    sourceCam = tk.Frame(camera_root)
    sourceCam.place(relx=0.0, rely=0.0, relheight=1.0, relwidth=1.0)
    sourceCam.configure(relief='groove')
    sourceCam.configure(borderwidth="2")
    sourceCam.configure(relief="groove")
    sourceCam.configure(background="#273746")
    sourceCam.configure(highlightbackground="#d9d9d9")
    sourceCam.configure(highlightcolor="black")

    sourceCamLable = tk.Label(sourceCam)
    sourceCamLable.place(relx=0.243, rely=0.058, height=56, width=254)
    sourceCamLable.configure(activebackground="#f9f9f9")
    sourceCamLable.configure(activeforeground="black")
    sourceCamLable.configure(anchor='w')
    sourceCamLable.configure(background="#273746")
    sourceCamLable.configure(compound='center')
    sourceCamLable.configure(disabledforeground="#a3a3a3")
    sourceCamLable.configure(font="-family {Segoe UI Black} -size 16 -weight bold")
    sourceCamLable.configure(foreground="#ffffff")
    sourceCamLable.configure(highlightbackground="#d9d9d9")
    sourceCamLable.configure(highlightcolor="black")
    sourceCamLable.configure(text='''Source Camera Settings''')

    cameraMode = tk.Label(sourceCam)
    cameraMode.place(relx=0.265, rely=0.289, height=38, width=117)
    cameraMode.configure(activebackground="#f9f9f9")
    cameraMode.configure(activeforeground="black")
    cameraMode.configure(anchor='w')
    cameraMode.configure(background="#273746")
    cameraMode.configure(compound='left')
    cameraMode.configure(disabledforeground="#a3a3a3")
    cameraMode.configure(font="-family {Segoe UI} -size 12 -weight bold")
    cameraMode.configure(foreground="#ffffff")
    cameraMode.configure(highlightbackground="#d9d9d9")
    cameraMode.configure(highlightcolor="black")
    cameraMode.configure(text='''Camera Mode''')

    fileDestination = tk.Label(sourceCam)
    fileDestination.place(relx=0.243, rely=0.434, height=49, width=132)
    fileDestination.configure(activebackground="#f9f9f9")
    fileDestination.configure(activeforeground="black")
    fileDestination.configure(anchor='w')
    fileDestination.configure(background="#273746")
    fileDestination.configure(compound='left')
    fileDestination.configure(disabledforeground="#a3a3a3")
    fileDestination.configure(font="-family {Segoe UI} -size 12 -weight bold")
    fileDestination.configure(foreground="#ffffff")
    fileDestination.configure(highlightbackground="#d9d9d9")
    fileDestination.configure(highlightcolor="black")
    fileDestination.configure(text='''File Destination''')

    camInput = tk.Entry(sourceCam)
    camInput.place(relx=0.575, rely=0.636, height=30, relwidth=0.4)
    camInput.configure(background="#EBEDEF")
    camInput.configure(disabledforeground="#a3a3a3")
    camInput.configure(font="TkFixedFont")
    camInput.configure(foreground="#000000")
    camInput.configure(highlightbackground="#d9d9d9")
    camInput.configure(highlightcolor="black")
    camInput.configure(insertbackground="black")
    camInput.configure(selectbackground="blue")
    camInput.configure(selectforeground="white")

    cameraModeList = tk.Listbox(sourceCam)
    cameraModeList.place(relx=0.575, rely=0.25, relheight=0.2
            , relwidth=0.3)
    cameraModeList.configure(background="#EBEDEF")
    cameraModeList.configure(disabledforeground="#a3a3a3")
    cameraModeList.configure(font="TkFixedFont")
    cameraModeList.configure(foreground="#000000")
    cameraModeList.configure(highlightbackground="#d9d9d9")
    cameraModeList.configure(highlightcolor="black")
    cameraModeList.configure(selectbackground="blue")
    cameraModeList.configure(selectforeground="white")
    l1 = ["IPcam","Camera","File"]
    for i in range(len(l1)):
        cameraModeList.insert(i+1,l1[i])
    # cameraModeList.select_set(2)

    fileDestiButton = tk.Button(sourceCam)
    fileDestiButton.place(relx=0.575, rely=0.462, height=34, relwidth=0.4)
    fileDestiButton.configure(activebackground="#ececec")
    fileDestiButton.configure(activeforeground="#000000")
    fileDestiButton.configure(background="#EBEDEF")
    fileDestiButton.configure(compound='left')
    fileDestiButton.configure(disabledforeground="#a3a3a3")
    fileDestiButton.configure(foreground="#000000")
    fileDestiButton.configure(highlightbackground="#d9d9d9")
    fileDestiButton.configure(highlightcolor="black")
    fileDestiButton.configure(pady="0")
    fileDestiButton.configure(text='''Location''')
    fileDestiButton.configure(command = browseFiles)

    camInputLabel = tk.Label(sourceCam)
    camInputLabel.place(relx=0.265, rely=0.607, height=49, width=112)
    camInputLabel.configure(activebackground="#f9f9f9")
    camInputLabel.configure(activeforeground="black")
    camInputLabel.configure(anchor='w')
    camInputLabel.configure(background="#273746")
    camInputLabel.configure(compound='left')
    camInputLabel.configure(disabledforeground="#a3a3a3")
    camInputLabel.configure(font="-family {Segoe UI} -size 12 -weight bold")
    camInputLabel.configure(foreground="#ffffff")
    camInputLabel.configure(highlightbackground="#d9d9d9")
    camInputLabel.configure(highlightcolor="black")
    camInputLabel.configure(text='''Camera IP''')

    camera_apply_button = tk.Button(sourceCam)
    camera_apply_button.place(relx=0.265, rely=0.844, height=34, width=97)
    camera_apply_button.configure(activebackground="#ececec")
    camera_apply_button.configure(activeforeground="#000000")
    camera_apply_button.configure(background="#EBEDEF")
    camera_apply_button.configure(compound='left')
    camera_apply_button.configure(disabledforeground="#a3a3a3")
    camera_apply_button.configure(foreground="#000000")
    camera_apply_button.configure(highlightbackground="#d9d9d9")
    camera_apply_button.configure(highlightcolor="black")
    camera_apply_button.configure(pady="0")
    camera_apply_button.configure(text='''Apply''')
    camera_apply_button.configure(command = apply_camera_settings)

    camera_exit_button = tk.Button(sourceCam)
    camera_exit_button.place(relx=0.575, rely=0.844, height=34, width=97)
    camera_exit_button.configure(activebackground="#ececec")
    camera_exit_button.configure(activeforeground="#000000")
    camera_exit_button.configure(background="#EBEDEF")
    camera_exit_button.configure(compound='left')
    camera_exit_button.configure(disabledforeground="#a3a3a3")
    camera_exit_button.configure(foreground="#000000")
    camera_exit_button.configure(highlightbackground="#d9d9d9")
    camera_exit_button.configure(highlightcolor="black")
    camera_exit_button.configure(pady="0")
    camera_exit_button.configure(text='''Exit''')
    camera_exit_button.configure(command = exit_camera_setting)
#############################################################################################################



def parameter_settings():
    def apply_parameter_setting():
        global pixel_limit_bw_cars,config_dict
        global region_line_up,region_line_down,distance_between_region,speed_limit
        line1 = LOI1_slider.get()
        line2 = LOI2_slider.get()
        region_line_up = int(line1/100*image_height)
        region_line_down = int(line2/100*image_height)
        config_dict["region_line_up"]=region_line_up
        config_dict["region_line_down"]=region_line_down
        
        pixel_limit_bw_cars = pixel_min_dist_slider.get()
        if(len(speedThreshInput.get())>0):
            speed_limit = int(speedThreshInput.get())
            config_dict["speed_limit"]=speed_limit
        else:
            # pass
            speed_limit = config_dict["speed_limit"]
        if(len(fixedDistInput.get())>0):
            distance_between_region = int(fixedDistInput.get())
            config_dict["distance_between_region"] = distance_between_region
        else:
            # pass
            distance_between_region = config_dict["distance_between_region"]
        
        
            # config_dict = (config_dict) 
            
    def exit_parameter_setting():
        parameter_root.destroy()
        
    parameter_root = tk.Toplevel(root)
    global pixel_limit_bw_cars
    global region_line_up,region_line_down,distance_between_region,speed_limit,image_height
    '''This class configures and populates the toplevel window.
       top is the toplevel containing window.'''
    _bgcolor = '#d9d9d9'  # X11 color: 'gray85'
    _fgcolor = '#000000'  # X11 color: 'black'
    _compcolor = '#d9d9d9' # X11 color: 'gray85'
    _ana1color = '#d9d9d9' # X11 color: 'gray85'
    _ana2color = '#ececec' # Closest X11 color: 'gray92'
    
    parameter_root.geometry("500x600+531+134")
    parameter_root.minsize(120, 1)
    parameter_root.maxsize(1540, 845)
    parameter_root.resizable(1,  1)
    parameter_root.title("parameter_rootlevel 1")
    parameter_root.configure(background="#d9d9d9")
    parameter_root.configure(highlightbackground="#d9d9d9")
    parameter_root.configure(highlightcolor="black")


    paraSet = tk.Frame(parameter_root)
    paraSet.place(relx=0.0, rely=0.0, relheight=1.0, relwidth=1.0)
    paraSet.configure(relief='groove')
    paraSet.configure(borderwidth="2")
    paraSet.configure(relief="groove")
    paraSet.configure(background="#273746")
    paraSet.configure(highlightbackground="#d9d9d9")
    paraSet.configure(highlightcolor="black")

    parameterSetLabel = tk.Label(paraSet)
    parameterSetLabel.place(relx=0.287, rely=0.01, height=30
            , width=208)
    parameterSetLabel.configure(activebackground="#f9f9f9")
    parameterSetLabel.configure(activeforeground="black")
    parameterSetLabel.configure(anchor='w')
    parameterSetLabel.configure(background="#273746")
    parameterSetLabel.configure(compound='center')
    parameterSetLabel.configure(disabledforeground="#a3a3a3")
    parameterSetLabel.configure(font="-family {Segoe UI Black} -size 16 -weight bold")
    parameterSetLabel.configure(foreground="#ffffff")
    parameterSetLabel.configure(highlightbackground="#d9d9d9")
    parameterSetLabel.configure(highlightcolor="black")
    parameterSetLabel.configure(text='''Parameter Settings''')

    fixedDistLabel = tk.Label(paraSet)
    fixedDistLabel.place(relx=0.112, rely=0.7, height=44, width=181)
    fixedDistLabel.configure(activebackground="#f9f9f9")
    fixedDistLabel.configure(activeforeground="black")
    fixedDistLabel.configure(anchor='w')
    fixedDistLabel.configure(background="#273746")
    fixedDistLabel.configure(compound='left')
    fixedDistLabel.configure(disabledforeground="#a3a3a3")
    fixedDistLabel.configure(font="-family {Segoe UI} -size 12 -weight bold")
    fixedDistLabel.configure(foreground="#ffffff")
    fixedDistLabel.configure(highlightbackground="#d9d9d9")
    fixedDistLabel.configure(highlightcolor="black")
    fixedDistLabel.configure(text='''Fixed Distance b/w LOI''')

    speedThreshLabel = tk.Label(paraSet)
    speedThreshLabel.place(relx=0.221, rely=0.8, height=45, width=138)

    speedThreshLabel.configure(activebackground="#f9f9f9")
    speedThreshLabel.configure(activeforeground="black")
    speedThreshLabel.configure(anchor='w')
    speedThreshLabel.configure(background="#273746")
    speedThreshLabel.configure(compound='left')
    speedThreshLabel.configure(disabledforeground="#a3a3a3")
    speedThreshLabel.configure(font="-family {Segoe UI} -size 12 -weight bold")
    speedThreshLabel.configure(foreground="#ffffff")
    speedThreshLabel.configure(highlightbackground="#d9d9d9")
    speedThreshLabel.configure(highlightcolor="black")
    speedThreshLabel.configure(text='''Speed Threshold''')

    fixedDistInput = tk.Entry(paraSet)
    fixedDistInput.place(relx=0.574, rely=0.7, height=30
            , relwidth=0.214)
    fixedDistInput.configure(background="#EBEDEF")
    fixedDistInput.configure(disabledforeground="#a3a3a3")
    fixedDistInput.configure(font="TkFixedFont")
    fixedDistInput.configure(foreground="#000000")
    fixedDistInput.configure(highlightbackground="#d9d9d9")
    fixedDistInput.configure(highlightcolor="black")
    fixedDistInput.configure(insertbackground="black")
    fixedDistInput.configure(selectbackground="blue")
    fixedDistInput.configure(selectforeground="white")

    speedThreshInput = tk.Entry(paraSet)
    speedThreshInput.place(relx=0.574, rely=0.8, height=30
            , relwidth=0.214)
    speedThreshInput.configure(background="#EBEDEF")
    speedThreshInput.configure(disabledforeground="#a3a3a3")
    speedThreshInput.configure(font="TkFixedFont")
    speedThreshInput.configure(foreground="#000000")
    speedThreshInput.configure(highlightbackground="#d9d9d9")
    speedThreshInput.configure(highlightcolor="black")
    speedThreshInput.configure(insertbackground="black")
    speedThreshInput.configure(selectbackground="blue")
    speedThreshInput.configure(selectforeground="white")
    
    LOI1_pos_label = tk.Label(paraSet)
    LOI1_pos_label.place(relx=0.112, rely=0.1, height=44, width=181)
    LOI1_pos_label.configure(activebackground="#f9f9f9")
    LOI1_pos_label.configure(activeforeground="black")
    LOI1_pos_label.configure(anchor='w')
    LOI1_pos_label.configure(background="#273746")
    LOI1_pos_label.configure(compound='left')
    LOI1_pos_label.configure(disabledforeground="#a3a3a3")
    LOI1_pos_label.configure(font="-family {Segoe UI} -size 12 -weight bold")
    LOI1_pos_label.configure(foreground="#ffffff")
    LOI1_pos_label.configure(highlightbackground="#d9d9d9")
    LOI1_pos_label.configure(highlightcolor="black")
    LOI1_pos_label.configure(text='''LOI 1 Position''')
                             
    LOI2_pos_label = tk.Label(paraSet)
    LOI2_pos_label.place(relx=0.112, rely=0.3, height=45, width=138)

    LOI2_pos_label.configure(activebackground="#f9f9f9")
    LOI2_pos_label.configure(activeforeground="black")
    LOI2_pos_label.configure(anchor='w')
    LOI2_pos_label.configure(background="#273746")
    LOI2_pos_label.configure(compound='left')
    LOI2_pos_label.configure(disabledforeground="#a3a3a3")
    LOI2_pos_label.configure(font="-family {Segoe UI} -size 12 -weight bold")
    LOI2_pos_label.configure(foreground="#ffffff")
    LOI2_pos_label.configure(highlightbackground="#d9d9d9")
    LOI2_pos_label.configure(highlightcolor="black")
    LOI2_pos_label.configure(text='''LOI 2 Position''')
    
    pixel_min_dist_label = tk.Label(paraSet)
    pixel_min_dist_label.place(relx=0.112, rely=0.5, height=45, width=138)

    pixel_min_dist_label.configure(activebackground="#f9f9f9")
    pixel_min_dist_label.configure(activeforeground="black")
    pixel_min_dist_label.configure(anchor='w')
    pixel_min_dist_label.configure(background="#273746")
    pixel_min_dist_label.configure(compound='left')
    pixel_min_dist_label.configure(disabledforeground="#a3a3a3")
    pixel_min_dist_label.configure(font="-family {Segoe UI} -size 12 -weight bold")
    pixel_min_dist_label.configure(foreground="#ffffff")
    pixel_min_dist_label.configure(highlightbackground="#d9d9d9")
    pixel_min_dist_label.configure(highlightcolor="black")
    pixel_min_dist_label.configure(text='''Pixel fixed dist''')
    
    var1 = tk.DoubleVar()
    var2 = tk.DoubleVar()
    var3 = tk.DoubleVar()
    
    LOI1_slider = ttk.Scale( paraSet, variable = var1, from_ = 1, to = 100, orient = tk.HORIZONTAL,length = 400) 
    LOI1_slider.grid(row = 0,column = 0,padx = 60,pady = 100)
    LOI1_slider.set(int(region_line_up/image_height*100))
    
    LOI2_slider = ttk.Scale( paraSet, variable = var2, from_ = 1, to = 100, orient = tk.HORIZONTAL,length = 400) 
    LOI2_slider.grid(row = 1,column = 0,padx = 60,pady = 0)
    LOI2_slider.set(int(region_line_down/image_height*100))
    
    pixel_min_dist_slider = ttk.Scale( paraSet, variable = var3, from_ = 1, to = 200, orient = tk.HORIZONTAL,length = 400) 
    pixel_min_dist_slider.grid(row = 2,column = 0,padx = 60,pady = 100)
    pixel_min_dist_slider.set(50)
    
    para_set_ApplyButton = tk.Button(paraSet)
    para_set_ApplyButton.place(relx=0.31, rely=0.9, height=34, width=67)
    para_set_ApplyButton.configure(activebackground="#ececec")
    para_set_ApplyButton.configure(activeforeground="#000000")
    para_set_ApplyButton.configure(background="#EBEDEF")
    para_set_ApplyButton.configure(compound='left')
    para_set_ApplyButton.configure(disabledforeground="#a3a3a3")
    para_set_ApplyButton.configure(foreground="#000000")
    para_set_ApplyButton.configure(highlightbackground="#d9d9d9")
    para_set_ApplyButton.configure(highlightcolor="black")
    para_set_ApplyButton.configure(pady="0")
    para_set_ApplyButton.configure(text='''Apply''')
    para_set_ApplyButton.configure(command = apply_parameter_setting)

    para_ExitButton = tk.Button(paraSet)
    para_ExitButton.place(relx=0.575, rely=0.9, height=34, width=67)
    para_ExitButton.configure(activebackground="#ececec")
    para_ExitButton.configure(activeforeground="#000000")
    para_ExitButton.configure(background="#EBEDEF")
    para_ExitButton.configure(compound='left')
    para_ExitButton.configure(disabledforeground="#a3a3a3")
    para_ExitButton.configure(foreground="#000000")
    para_ExitButton.configure(highlightbackground="#d9d9d9")
    para_ExitButton.configure(highlightcolor="black")
    para_ExitButton.configure(pady="0")
    para_ExitButton.configure(text='''Exit''')
    para_ExitButton.configure(command = exit_parameter_setting)


#############################################################################################################
def database_setting():
    
    def apply_database_setting():
        global auth_token
        if(len(dataLinkInput.get())>0):
            auth_token = str(dataLinkInput.get())
            config_dict["auth_token"]=auth_token
        else:
            # pass
            auth_token = config_dict["auth_token"]
        setup_database()
        
    def exit_database_setting():
        db_root.destroy()
    
    '''This class configures and populates the toplevel window.
    top is the toplevel containing window.'''
    
    _bgcolor = '#d9d9d9'  # X11 color: 'gray85'
    _fgcolor = '#000000'  # X11 color: 'black'
    _compcolor = '#d9d9d9' # X11 color: 'gray85'
    _ana1color = '#d9d9d9' # X11 color: 'gray85'
    _ana2color = '#ececec' # Closest X11 color: 'gray92'
    
    db_root = tk.Toplevel(root)
    db_root.geometry("452x326+531+134")
    db_root.minsize(120, 1)
    db_root.maxsize(1540, 845)
    db_root.resizable(1,  1)
    db_root.title("db_rootlevel 1")
    db_root.configure(background="#d9d9d9")
    db_root.configure(highlightbackground="#d9d9d9")
    db_root.configure(highlightcolor="black")

    db_root = db_root

    db_frame = tk.Frame(db_root)
    db_frame.place(relx=0.0, rely=0.0, relheight=1.0, relwidth=1.0)
    db_frame.configure(relief='groove')
    db_frame.configure(borderwidth="2")
    db_frame.configure(relief="groove")
    db_frame.configure(background="#273746")
    db_frame.configure(highlightbackground="#d9d9d9")
    db_frame.configure(highlightcolor="black")

    databaseSetLabel = tk.Label(db_frame)
    databaseSetLabel.place(relx=0.288, rely=0.061, height=53, width=214)

    databaseSetLabel.configure(activebackground="#f9f9f9")
    databaseSetLabel.configure(activeforeground="black")
    databaseSetLabel.configure(anchor='w')
    databaseSetLabel.configure(background="#273746")
    databaseSetLabel.configure(compound='center')
    databaseSetLabel.configure(disabledforeground="#a3a3a3")
    databaseSetLabel.configure(font="-family {Segoe UI Black} -size 16 -weight bold")
    databaseSetLabel.configure(foreground="#ffffff")
    databaseSetLabel.configure(highlightbackground="#d9d9d9")
    databaseSetLabel.configure(highlightcolor="black")
    databaseSetLabel.configure(text='''Database Settings''')

    dataLinkLabel = tk.Label(db_frame)
    dataLinkLabel.place(relx=0.243, rely=0.276, height=46, width=127)
    dataLinkLabel.configure(activebackground="#f9f9f9")
    dataLinkLabel.configure(activeforeground="black")
    dataLinkLabel.configure(anchor='w')
    dataLinkLabel.configure(background="#273746")
    dataLinkLabel.configure(compound='left')
    dataLinkLabel.configure(disabledforeground="#a3a3a3")
    dataLinkLabel.configure(font="-family {Segoe UI} -size 12 -weight bold")
    dataLinkLabel.configure(foreground="#ffffff")
    dataLinkLabel.configure(highlightbackground="#d9d9d9")
    dataLinkLabel.configure(highlightcolor="black")
    dataLinkLabel.configure(text='''Datasheet Link''')

    dataLinkInput = tk.Entry(db_frame)
    dataLinkInput.place(relx=0.575, rely=0.307, height=30
            , relwidth=0.208)
    dataLinkInput.configure(background="#EBEDEF")
    dataLinkInput.configure(disabledforeground="#a3a3a3")
    dataLinkInput.configure(font="TkFixedFont")
    dataLinkInput.configure(foreground="#000000")
    dataLinkInput.configure(highlightbackground="#d9d9d9")
    dataLinkInput.configure(highlightcolor="black")
    dataLinkInput.configure(insertbackground="black")
    dataLinkInput.configure(selectbackground="blue")
    dataLinkInput.configure(selectforeground="white")

    ApplyButton = tk.Button(db_frame)
    ApplyButton.place(relx=0.31, rely=0.583, height=34, width=67)
    ApplyButton.configure(activebackground="#ececec")
    ApplyButton.configure(activeforeground="#000000")
    ApplyButton.configure(background="#EBEDEF")
    ApplyButton.configure(compound='left')
    ApplyButton.configure(disabledforeground="#a3a3a3")
    ApplyButton.configure(foreground="#000000")
    ApplyButton.configure(highlightbackground="#d9d9d9")
    ApplyButton.configure(highlightcolor="black")
    ApplyButton.configure(pady="0")
    ApplyButton.configure(text='''Apply''')
    ApplyButton.configure(command = apply_database_setting)

    db_exit_button = tk.Button(db_frame)
    db_exit_button.place(relx=0.575, rely=0.583, height=34, width=67)
    db_exit_button.configure(activebackground="#ececec")
    db_exit_button.configure(activeforeground="#000000")
    db_exit_button.configure(background="#EBEDEF")
    db_exit_button.configure(compound='left')
    db_exit_button.configure(disabledforeground="#a3a3a3")
    db_exit_button.configure(foreground="#000000")
    db_exit_button.configure(highlightbackground="#d9d9d9")
    db_exit_button.configure(highlightcolor="black")
    db_exit_button.configure(pady="0")
    db_exit_button.configure(text='''Exit''')
    db_exit_button.config(command = exit_database_setting)






############################################################################################################







    



main_frame = tk.Frame(root)
main_frame.place(relx=0.0, rely=0.0, relheight=1.0, relwidth=1.0)
main_frame.configure(relief='groove')
main_frame.configure(borderwidth="2")
main_frame.configure(relief="groove")
main_frame.configure(background="#6699CC")
main_frame.configure(highlightbackground="#d9d9d9")
main_frame.configure(highlightcolor="black")

# main_frame.pack()

Video_Frame = tk.Frame(main_frame,width=1900, height=1000)

# Video_Frame.place(relx=0.01, rely=0.071, relheight=0.855
#         , relwidth=0.771)
Video_Frame.configure(relief='groove')
# Video_Frame.configure(foreground="black")
# Video_Frame.configure(text='''Video Stream''')
Video_Frame.configure(background="#ffffff")
Video_Frame.configure(highlightbackground="#d9d9d9")
Video_Frame.configure(highlightcolor="black")
# Video_Frame.pack()
Video_Frame.grid(row=0, column=0, padx=20, pady=100)


video_label = tk.Label(Video_Frame)
video_label.grid(row=1, column=0, padx=50, pady=70)


title_frame = tk.Label(main_frame)
title_frame.place(relx=0.01, rely=0.02, height=44, width=1473)
title_frame.configure(activebackground="#f9f9f9")
title_frame.configure(activeforeground="black")
title_frame.configure(background="#000000")
title_frame.configure(disabledforeground="#a3a3a3")
title_frame.configure(font="-family {Segoe UI} -size 22 -weight bold")
title_frame.configure(foreground="#ffffff")
title_frame.configure(highlightbackground="#d9d9d9")
title_frame.configure(highlightcolor="black")
title_frame.configure(text='''Speed Violation Detection System''')
# title_frame.pack()

pause_button = tk.Button(main_frame)
pause_button.place(relx=0.344, rely=0.938, height=53, width=106)
pause_button.configure(activebackground="#ececec")
pause_button.configure(activeforeground="#000000")
pause_button.configure(background="#ffffff")
pause_button.configure(disabledforeground="#a3a3a3")
pause_button.configure(font="-family {Segoe UI} -size 14 -weight bold")
pause_button.configure(foreground="#000000")
pause_button.configure(highlightbackground="#d9d9d9")
pause_button.configure(highlightcolor="black")
pause_button.configure(pady="0")
pause_button.configure(text='''Pause''')
pause_button.configure(command = pausee)
# pause_button.pack()

play_button = tk.Button(main_frame)
play_button.place(relx=0.411, rely=0.938, height=53, width=106)
play_button.configure(activebackground="#ececec")
play_button.configure(activeforeground="#000000")
play_button.configure(background="#ffffff")
play_button.configure(disabledforeground="#a3a3a3")
play_button.configure(font="-family {Segoe UI} -size 14 -weight bold")
play_button.configure(foreground="#000000")
play_button.configure(highlightbackground="#d9d9d9")
play_button.configure(highlightcolor="black")
play_button.configure(pady="0")
play_button.configure(text='''Play''')
play_button.configure(command = playy)
# play_button.pack()



settings = tk.LabelFrame(main_frame)
settings.place(relx=0.786, rely=0.404, relheight=0.562
        , relwidth=0.208)
settings.configure(relief='groove')
settings.configure(foreground="white")
settings.configure(text='''Settings''')
settings.configure(background="#6699CC")
settings.configure(highlightbackground="#d9d9d9")
settings.configure(highlightcolor="black")
# settings.pack()



source_cam_setting_button = tk.Button(settings)
source_cam_setting_button.place(relx=0.175, rely=0.1, height=53, width=106
        , bordermode='ignore')
source_cam_setting_button.configure(activebackground="#ececec")
source_cam_setting_button.configure(activeforeground="#000000")
source_cam_setting_button.configure(background="#ffffff")
source_cam_setting_button.configure(disabledforeground="#a3a3a3")
source_cam_setting_button.configure(font="-family {Segoe UI} -size 14 -weight bold")
source_cam_setting_button.configure(foreground="#000000")
source_cam_setting_button.configure(highlightbackground="#d9d9d9")
source_cam_setting_button.configure(highlightcolor="black")
source_cam_setting_button.configure(pady="0")
source_cam_setting_button.configure(text='''Camera''')
source_cam_setting_button.configure(command = camera_setting)

parameters_setting_button = tk.Button(settings)
parameters_setting_button.place(relx=0.175, rely=0.3, height=53, width=106
        , bordermode='ignore')
parameters_setting_button.configure(activebackground="#ececec")
parameters_setting_button.configure(activeforeground="#000000")
parameters_setting_button.configure(background="#ffffff")
parameters_setting_button.configure(disabledforeground="#a3a3a3")
parameters_setting_button.configure(font="-family {Segoe UI} -size 14 -weight bold")
parameters_setting_button.configure(foreground="#000000")
parameters_setting_button.configure(highlightbackground="#d9d9d9")
parameters_setting_button.configure(highlightcolor="black")
parameters_setting_button.configure(pady="0")
parameters_setting_button.configure(text='''Parameters''')
parameters_setting_button.configure(command = parameter_settings)


database_setting_button = tk.Button(settings)
database_setting_button.place(relx=0.175, rely=0.5, height=53, width=106
        , bordermode='ignore')
database_setting_button.configure(activebackground="#ececec")
database_setting_button.configure(activeforeground="#000000")
database_setting_button.configure(background="#ffffff")
database_setting_button.configure(disabledforeground="#a3a3a3")
database_setting_button.configure(font="-family {Segoe UI} -size 14 -weight bold")
database_setting_button.configure(foreground="#000000")
database_setting_button.configure(highlightbackground="#d9d9d9")
database_setting_button.configure(highlightcolor="black")
database_setting_button.configure(pady="0")
database_setting_button.configure(text='''Database''')
database_setting_button.configure(command = database_setting)


# apply_button.pack()

exit_button = tk.Button(settings)
exit_button.place(relx=0.576, rely=0.88, height=53, width=106
        , bordermode='ignore')
exit_button.configure(activebackground="#ececec")
exit_button.configure(activeforeground="#000000")
exit_button.configure(background="#ffffff")
exit_button.configure(disabledforeground="#a3a3a3")
exit_button.configure(font="-family {Segoe UI} -size 14 -weight bold")
exit_button.configure(foreground="#000000")
exit_button.configure(highlightbackground="#d9d9d9")
exit_button.configure(highlightcolor="black")
exit_button.configure(pady="0")
exit_button.configure(text='''Exit''')
exit_button.configure(command = exitt)
# exit_button.pack()



play_video()
root.mainloop()







